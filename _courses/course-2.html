<h1 class="h5 yellow">Foundation of Machine Learning</h1>
<div class="h6 text-white course-summary">
        This course was provided by Prof. <a class="yellow" href="https://scholar.google.com/citations?user=5wuvTfoAAAAJ&hl=en">Moustapha Cisse</a>. The course had two parts: Statistical Learning Theory and an introduction to Deep Learning. In the first part, we explored theoretical aspects of machine learning, particularly statistical learning theory, covering both supervised and unsupervised learning. We discussed the ERM problem, bias-variance tradeoff, overfitting and underfitting, linear regression, classification, generalized linear models, and dimensionality reduction techniques such as:
        <ul class="h6 text-white">
          <li>Random projections</li>
          <li>Principal Component Analysis</li>
          <li>Canonical Correlation Analysis</li>
        </ul>
        In the second part, we covered neural networks, weight initialization, CNNs, RNNs, attention mechanisms, and transformers.<br>
        Please find <a class="yellow" href="here">here</a> the materials I used and some code I implemented. Also, check out my tutorials below.
</div>